{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51599110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be5fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [name for name in os.listdir('data') if os.path.isdir(os.path.join('data', name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3d4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of error from sequenceID and llda\n",
    "def get_err(evaluation_df, seqID, llda):\n",
    "    # get sub eval_df of seqID\n",
    "    eval_df = evaluation_df[evaluation_df['sequenceID'] == seqID]\n",
    "\n",
    "    n_labels = 0\n",
    "    n_errs = 0\n",
    "    if(eval_df.shape[0] > 0):\n",
    "        # get right row\n",
    "        position = np.logical_and(eval_df['min.log.lambda'] <= llda, llda < eval_df['max.log.lambda'])\n",
    "        row = eval_df[position]\n",
    "\n",
    "        # get total labels and total errors\n",
    "        n_labels = row['labels'].item()\n",
    "        n_errs = row['errors'].item()\n",
    "\n",
    "    return n_labels, n_errs\n",
    "\n",
    "def get_acc(eval_df, lldas_df):\n",
    "    total_err = 0\n",
    "    total_labels = 0\n",
    "    for seqID in lldas_df['sequenceID']:\n",
    "        llda = lldas_df[lldas_df['sequenceID'] == seqID]['pred'].item()\n",
    "        n_labels, n_errs = get_err(eval_df, seqID, llda)\n",
    "        total_labels += n_labels\n",
    "        total_err += n_errs\n",
    "    acc = (total_labels - total_err)/total_labels\n",
    "    return acc*100\n",
    "\n",
    "def add_row_to_csv(file_path, columns, row):\n",
    "    try:\n",
    "        existing_df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        existing_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    method = row[0]\n",
    "    fold = row[1]\n",
    "\n",
    "    if not existing_df.empty:\n",
    "        if any((existing_df['method'] == method) & (existing_df['fold'] == fold)):\n",
    "            print(f\"Warning: Entry for method '{method}' and fold '{fold}' already exists in '{file_path}'. Row not added.\")\n",
    "            return\n",
    "\n",
    "    # Add row safely without concat\n",
    "    existing_df.loc[len(existing_df)] = row\n",
    "\n",
    "    existing_df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Load the necessary CSV files\n",
    "    fold_df = pd.read_csv(f'data/{dataset}/folds.csv')\n",
    "    evaluation_df = pd.read_csv(f'data/{dataset}/evaluation.csv', na_values=['#NAME?'])\n",
    "    evaluation_df['min.log.lambda'] = evaluation_df['min.log.lambda'].fillna(-np.inf)\n",
    "\n",
    "    for test_fold in sorted(fold_df['fold'].unique()):\n",
    "        pred_df = pd.read_csv(f'model/final_predictions/{dataset}.{test_fold}.csv')\n",
    "        eval_df = evaluation_df[evaluation_df['sequenceID'].isin(fold_df[fold_df['fold'] == test_fold]['sequenceID'])]\n",
    "        \n",
    "        # Calculate the accuracy using the averaged predictions\n",
    "        acc = get_acc(eval_df, pred_df)\n",
    "        \n",
    "        # Save the result to the CSV file\n",
    "        add_row_to_csv('csvs/csvs_proposed/' + dataset + '.csv', ['method', 'fold', 'acc'], ['cnn', test_fold, acc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
